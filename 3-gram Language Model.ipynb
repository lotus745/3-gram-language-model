{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " f = open('D:/Text Analytics/MRcorpus.txt',encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "txt_dt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "import codecs\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_dt = re.sub(r\"[^\\u0900-\\u0963,\\u0970-\\u097F, \\u002E]+\", \" \", txt_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "words = word_tokenize(txt_dt)\n",
    "#cfdist = FreqDist(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['औदुंबर', 'कविता', 'औदुंबर', 'रसग्रहण', 'एखाद्या']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#grams3 = ngrams(words, 3, pad_right=True, pad_left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sents_mr = [element.strip() for element in txt_dt.split('. ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['औदुंबर  कविता  औदुंबर रसग्रहण  एखाद्या कुशल चित्रकाराने कुंचल्याच्या अवघ्या चार सहा फटकाऱ्यांसरशी एखादे सुरेख चित्र निर्माण करावे तद्वत अवघ्या आठ ओळीत बालकवींनी एक सुंदर निसर्गचित्र शब्दांच्या कुंचल्याने या कवितेत रेखाटलेले आहे',\n",
       " 'हे चित्र रंगविताना कवीने विविध रंग वापरलेले आढळतील',\n",
       " 'निळासावळा झरा, शेतमळ्यांची हिरवी गरदी, पांढरी पायवाट व काळा डोह मोजक्या रंगांनी शब्दांच्या चौकटीत बसविलेले हे एक साधे व जिवंत चित्र आहे',\n",
       " 'बालकवींची रंगदृष्टी येथे आपल्या प्रत्ययास येते',\n",
       " 'पहिल्या चार ओळींत टेकड्या, गाव, शेतमळे व झरा यांनी व्यापलेले विहंगम दृश्य दिसते']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents_mr[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = defaultdict(lambda: defaultdict(lambda: 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for sentence in sents_mr:\n",
    "    wrd3 = word_tokenize(sentence)\n",
    "    gg3 = ngrams(wrd3, 3, pad_right=True, pad_left=True)\n",
    "    for w1, w2, w3 in gg3:\n",
    "        model[(w1, w2)][w3] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_key(val): \n",
    "    check = max(list(model[val[0],val[1]].values()))\n",
    "    for key, value in model[val[0],val[1]].items(): \n",
    "         if check == value: \n",
    "             return key \n",
    "  \n",
    "    return \"key doesn't exist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'कविता'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_key([\"एक\", \"सुंदर\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "एक सुंदर कविता लिहिली\n"
     ]
    }
   ],
   "source": [
    "first_two = \"एक सुंदर\"\n",
    "\n",
    "full_sent = copy.deepcopy(first_two)\n",
    "\n",
    "in1 = word_tokenize(first_two)\n",
    "if get_key(in1) != None:\n",
    "    full_sent += \" \" + get_key(in1)\n",
    "\n",
    "next_two = [full_sent.split()[-2], full_sent.split()[-1]]\n",
    "\n",
    "sentence_finished = False\n",
    "\n",
    "i = 3\n",
    "\n",
    "while ((not sentence_finished) & (i <= 25)):\n",
    "    if get_key(next_two) == None:\n",
    "        break\n",
    "    full_sent += \" \" + get_key(next_two)\n",
    "    next_two = [full_sent.split()[-2], full_sent.split()[-1]]\n",
    "    i += 1\n",
    "    if next_two == [None, None]:\n",
    "      sentence_finished = True\n",
    "\n",
    "print(full_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "एक सुंदर इलाज हजारो वर्षांपासून आहे\n"
     ]
    }
   ],
   "source": [
    "# code courtesy of https://nlpforhackers.io/language-models/\n",
    "\n",
    "import random\n",
    "\n",
    "# starting words\n",
    "text = [\"एक\", \"सुंदर\"]\n",
    "sentence_finished = False\n",
    " \n",
    "while not sentence_finished:\n",
    "  # select a random probability threshold  \n",
    "  r = random.random()\n",
    "  accumulator = .0\n",
    "\n",
    "  for word in model[tuple(text[-2:])].keys():\n",
    "      accumulator += model[tuple(text[-2:])][word]\n",
    "      # select words that are above the probability threshold\n",
    "      if accumulator >= r:\n",
    "          text.append(word)\n",
    "          break\n",
    "\n",
    "  if text[-2:] == [None, None]:\n",
    "      sentence_finished = True\n",
    " \n",
    "print (' '.join([t for t in text if t]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
